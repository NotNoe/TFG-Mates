\chapter{Introducción}
\label{cap:introduccion}


Desde el inicio de la computación, se han desarrollado métodos numéricos para aproximar soluciones de ecuaciones que no podemos resolver de manera analítica. Con el auge de la computación en \ac{GPU}, que permite computar los datos en paralelo, se pueden implementar estos mismos métodos de formas que, como comprobaremos al final de este trabajo, son mucho más eficientes.

\section{\acs{CPU} vs. \acs{GPU}}

La \ac{GPU} en un componente hardware que tienen todos los ordenadores actuales optimizado para hacer los cálculos relacionados con procesamiento de imágenes.

Tradicionalmente, las \acs{GPU}s solo se usaban para procesar gráficos, pero en estos últimos años, se han empezado a aprovechar las características de las \acs{GPU}s que las hacen buenas para procesar imágenes con otros fines.

Normalmente, cuando ejecutamos un programa lo hacemos en la \ac{CPU}, que es la unidad de procesamiento que se encarga de la mayoría de las tareas que realiza el ordenador. Existen mecanismos (como hilos y procesos) para realizar ejecuciones en paralelo en la \ac{CPU}, y estos también pueden mejorar la eficiencia de los algoritmos, pero en mucha menos medida.

El motivo de esto son los \emph{cores}. Toda unidad de procesamiento (\ac{CPU} o \ac{GPU}) tiene un número limitado de núcleos, que son la parte de la unidad que realiza las operaciones. Aunque hagamos que un programa utilice cien hilos para hacerlo más eficiente, si luego lo corremos en una \ac{CPU} con solo cuatro núcleos, el número máximo de hilos que verdaderamente pueden estar ejecutándose a la vez es cuatro. Además, cada vez que un core tiene que cambiar de un hilo a otro, se tienen que realizar una serie de tareas que pueden acabar afectando al rendimiento. La ventaja de las \acs{GPU}s respecto a las \ac{CPU}s es que tienen un gran número de núcleos (aunque funcionan más despacio y solo pueden ejecutar instrucciones simples).

Veamos, por ejemplo, los números concretos que tiene la máquina donde se realizarán las pruebas rendimiento de este trabajo (para ver las especificaciones completas, ver \ref{subsec:plan_trabajo}).

El procesador tiene 6 núcleos que funcionan a una frecuencia de 2.9GHz. Esto significa que el la \ac{CPU} puede realizar $1,74\times10^{10}$ operaciones en un segundo. Por otro lado, la \ac{GPU} tiene 5888 núcleos que funcionan a 1.5GHz, por lo que puede realizar $8,832\times10^{12}$ operaciones por segundo, esto es una mejora de dos órdenes de magnitud\footnote{En realidad esta mejora de eficiencia viene con un coste. Los núcleos de la \ac{GPU} son mucho más simples que los de la \ac{CPU} y sólo pueden ejecutar instrucciones básicas, por lo que si quisiéramos ejecutar un programa con instrucciones muy complejas en la \ac{GPU}, necesitaría traducir las instrucciones complejas en muchas instrucciones simples y eso contrarrestaría la mejora, por eso las \ac{GPU}s son mejores solo para ciertas cosas}.


\section{Objetivos}
En este trabajo pretendemos estudiar la implementación de métodos de diferencias finitas en la \ac{GPU} y su mejora de eficiencia en las ecuaciones de \emph{Laplace} (en dos dimensiones), del calor (en una y dos dimensiones) y de ondas (en una y dos dimensiones), que son las siguientes:

\begin{multicols}{3}
	\centering
	Laplace:
	\begin{equation}
		\frac{\partial^2u}{\partial x^2}+\frac{\partial^2u}{\partial y^2}=0
	\end{equation}
	Calor (1D):
	\begin{equation}
		\frac{\partial u}{\partial t} = \kappa\frac{\partial ^2u}{\partial x^2} 
	\end{equation}
Calor (2D):
	\begin{equation}
		\frac{\partial u}{\partial t}=\kappa\left(\frac{\partial^2u}{\partial x^2}+\frac{\partial^2u}{\partial y^2}\right)
	\end{equation}
Ondas (1D):
	\begin{equation}
		\frac{\partial^2u}{\partial t^2}=v^2\frac{\partial^2u}{\partial x^2}
	\end{equation}
Ondas (2D):
	\begin{equation}
		\frac{\partial^2u}{\partial t^2}=v^2\left(\frac{\partial^2u}{\partial x^2}+\frac{\partial^2u}{\partial y^2}\right)
	\end{equation}
\end{multicols}

Dónde $\kappa>0$ se conoce como el coeficiente de difusividad térmica y $v^2>0$ es la velocidad de propagación de la onda en el medio. 

\section{Nociones generales}
Como hemos comentado, todos los métodos numéricos que vamos a desarrollar en este trabajo están basados en una técnica conocida como \ac{MDF}. Esta técnica (que desarrollaremos más en el Capítulo \ref{cap:dif_fin}), se basa en aproximar las distintas derivadas de una función por un cociente incremental. Luego, estudiamos el error que introduce esa aproximación en cada uno de los casos concretos para ver cuándo podemos asegurar que estos métodos propuestos convergen.

\section{Plan de trabajo} \label{subsec:plan_trabajo}
Para realizar el estudio, los lenguajes de programación que utilizaremos serán \ac{CUDA} (una extensión de C++ que permite la ejecución de funciones -llamadas \emph{kernels}- en la \ac{GPU}) y Python, que tiene una librería llamada pycuda para ejecutar código \ac{CUDA}. Además, todos los programas aquí mostrados y los resultados obtenidos serán ejecutados en la misma máquina, con las siguientes especificaciones, no obstante, los programas están pensados para poder ejecutarse en cualquier máquina\footnote{Si se desea utilizar el script \textit{generateMod.py} en un sistema basado en Windows o MAC, podría ser necesario hacer unos pocos cambios para adaptarse a las distintas formas de nombrar las rutas en estos sistemas.}

\begin{description}
	\item[Procesador] Intel© Core™ i5-10400F \ac{CPU} @ 2.90GHz × 6
	\item[RAM] 15.5 GiB
	\item[\ac{GPU}] NVIDIA Corporation GA104 [GeForce RTX 3070]
	\item[SO] Linux Mint 21.3 Cinnamon
\end{description}

En el Capítulo \ref{cap:computacion} explicaremos cómo ejecutar programas en la \ac{GPU} usando la librería pycuda (para lo que primero debemos de entender como programar en \ac{CUDA}), seguido de un par de programas para familiarizarnos con las librerías y ver que, en efecto, pueden acelerar los tiempos de ejecución.

En los Capítulos \ref{cap:heat}, \ref{cap:wave} y \ref{cap:laplace} demostraremos los resultados necesarios para asegurar la existencia y unicidad de las ecuaciones del calor, ondas y Laplace respectivamente. Una vez asegurada la existencia y unicidad, propondremos un esquema numérico para aproximar la solución en los puntos de la malla y demostraremos su convergencia (que generalmente dependerán de los parámetros con los que construyamos la maya).

Después de haber propuesto los métodos numéricos, en el Capítulo \ref{cap:alg_clas} los implementaremos en Python utilizando computación clásica, y analizaremos la eficiencia de estos

Por último, en el Capítulo \ref{cap:alg_gpu} implementaremos los algoritmos en \ac{CUDA} aprovechándonos de la computación paralela para hacerlos más rápidos que sus equivalentes en Python, y tras esto analizaremos el incremento de eficiencia que nos ha proporcionado la ac{GPU}.
